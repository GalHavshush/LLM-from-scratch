# LLM From Scratch

> A from-scratch implementation of a GPT-style large language model in PyTorch for educational and research purposes.

**Work in Progress**

This project is currently under active development as part of a deeper exploration into modern NLP and Transformer-based language models.

## Project Overview

The goal of this project is to build and understand GPT-style architectures from the ground up, focusing on implementation details, model mechanics, and practical experimentation rather than relying solely on high-level libraries.

This work is guided in part by the book:

**Build a Large Language Model (From Scratch)**  
Sebastian Raschka

The project expands on the bookâ€™s concepts with additional experimentation, implementation practice, and documentation.

## Notebooks

The `notebooks/` folder contains exploratory work supporting the main implementation:

- **01 Working with Text Data**  
  Data preprocessing, tokenization, and dataset preparation for language modeling.  
- **02 Coding Attention Mechanisms**  
  Implementation of attention concepts from first principles.  
- **03 Implementing a GPT Model**  
  Building a simplified GPT-style model and experimenting with text generation.  
