{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8745407c",
   "metadata": {},
   "source": [
    "# 4. Pretraining On Unlabeled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35facadc",
   "metadata": {},
   "source": [
    "## 4.1 Evaluating Generative Text Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42323e59",
   "metadata": {},
   "source": [
    "### 4.1.1 GPT-124M Configuration Setup and Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e4fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_modules import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 256,  # Context length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n_heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False        # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ced3198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe10fa",
   "metadata": {},
   "source": [
    "### 4.1.2 Text-to-Tokens, Generation, and Decoding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad81020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from gpt_modules import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'}) # Encode text into token IDs (allow GPT special tokens if present)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # Add batch dimension → shape becomes (1, seq_len)\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # Remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist()) # Convert token IDs back to readable text\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Generate new tokens autoregressively\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "# Decode generated token IDs back into text\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da246d",
   "metadata": {},
   "source": [
    "### 4.1.3 Calculating The Text Generation Loss: Cross-Entropy And Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6718e10",
   "metadata": {},
   "source": [
    "Example Input and Target Token Batches for Next-Token Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e6dcbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([\n",
    "    [16833, 3626, 6100],   # \"every effort moves\"\n",
    "    [40,    1107, 588]     # \"I really like\"\n",
    "])\n",
    "\n",
    "targets = torch.tensor([\n",
    "    [3626, 6100, 345],     # \"effort moves you\"\n",
    "    [1107, 588, 11311]     # \"really like chocolate\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8e773",
   "metadata": {},
   "source": [
    "Computing Token Probabilities from Model Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa0ba999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():                # Disable gradients for inference\n",
    "    logits = model(inputs)           # Forward pass → raw logits (batch, seq_len, vocab_size)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)  # Convert logits to probabilities over vocabulary\n",
    "print(probas.shape)                      # Expected: (batch_size, seq_len, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddc3c9",
   "metadata": {},
   "source": [
    "Selecting Most Probable Token IDs (Greedy Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c16621df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)  \n",
    "# Select highest-probability token at each position (greedy decoding)\n",
    "\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c0554",
   "metadata": {},
   "source": [
    "Comparing Target Tokens with Model Predictions (Decoded Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b21a93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "# Decode target tokens for batch 1\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "\n",
    "# Decode predicted token IDs for batch 1\n",
    "# Flatten removes extra dimension from argmax output\n",
    "print(f\"Outputs batch 1: \"\n",
    "      f\"{token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563cdc6",
   "metadata": {},
   "source": [
    "Extracting Model Probabilities for Target Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bfeeca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "# Get probabilities assigned to the correct target tokens for batch 1\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "# Same extraction for batch 2\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6bba26",
   "metadata": {},
   "source": [
    "Computing Log Probabilities of Target Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c1b63a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Combine probabilities from both batches and convert to log-probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "\n",
    "print(log_probas)  # Log probabilities used in cross-entropy / likelihood calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7be1b0f",
   "metadata": {},
   "source": [
    "Computing Average Log Probability of Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00299cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Compute average log probability across all target tokens\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "\n",
    "print(avg_log_probas)  # Higher (less negative) means better predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dcd64a",
   "metadata": {},
   "source": [
    "Computing Negative Average Log Probability (Loss Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f58508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Convert average log probability into negative log-likelihood (loss)\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "\n",
    "print(neg_avg_log_probas)  # Equivalent to cross-entropy style loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ca89f",
   "metadata": {},
   "source": [
    "Inspecting Logits and Target Tensor Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7c628f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)    # Expected: (batch_size, seq_len, vocab_size)\n",
    "print(\"Targets shape:\", targets.shape)  # Expected: (batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5b7abf",
   "metadata": {},
   "source": [
    "Flattening Logits and Targets for Loss Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c434ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# Merge batch and sequence dimensions to match loss function expectations\n",
    "logits_flat = logits.flatten(0, 1)   # Shape: (batch_size * seq_len, vocab_size)\n",
    "targets_flat = targets.flatten()     # Shape: (batch_size * seq_len)\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943f0f5",
   "metadata": {},
   "source": [
    "Computing Cross-Entropy Loss for Next-Token Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf77b225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Compute cross-entropy loss between predicted logits and true token IDs\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "\n",
    "print(loss)  # Standard language modeling loss (negative log-likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f44cf2",
   "metadata": {},
   "source": [
    "### 4.1.4 Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf69758",
   "metadata": {},
   "source": [
    "Loading Text Dataset and Counting Characters & Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33b0533e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../dataset/the_verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "    \n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b1d218",
   "metadata": {},
   "source": [
    "Splitting Dataset into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "230906a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90                              # Use 90% of data for training\n",
    "split_idx = int(train_ratio * len(text_data))   # Compute split index\n",
    "\n",
    "train_data = text_data[:split_idx]              # Training portion of text\n",
    "val_data = text_data[split_idx:]                # Validation portion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece679e",
   "metadata": {},
   "source": [
    "Creating Training and Validation DataLoaders for GPT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4f12f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_modules import create_dataloader_v1\n",
    "torch.manual_seed(123)  # Ensure reproducible dataset shuffling\n",
    "\n",
    "# Training DataLoader\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],  # Sequence length\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],      # Non-overlapping chunks\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Validation DataLoader\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63f265",
   "metadata": {},
   "source": [
    "Inspecting Batch Shapes from Training and Validation DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9e8eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)   # Input tokens and target tokens per batch\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)   # Same check for validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209b6f3",
   "metadata": {},
   "source": [
    "Batch and Dataset Loss Computation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6d815e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy loss for a single batch.\n",
    "\n",
    "    Moves data to device, runs forward pass,\n",
    "    flattens logits/targets for token-level loss.\n",
    "    \"\"\"\n",
    "\n",
    "    input_batch = input_batch.to(device)     # Move inputs to CPU/GPU\n",
    "    target_batch = target_batch.to(device)   # Move targets to same device\n",
    "    logits = model(input_batch)              # Forward pass → (batch, seq_len, vocab_size)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten()) # Flatten batch + sequence dims for cross-entropy loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"\n",
    "    Compute average loss over a DataLoader.\n",
    "\n",
    "    Optionally limit evaluation to a subset of batches\n",
    "    (useful for faster validation during training).\n",
    "    \"\"\"\n",
    "\n",
    "    total_loss = 0.\n",
    "\n",
    "    # Handle empty loader edge case\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    # Use all batches unless specified otherwise\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    # Iterate over batches\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()   # Accumulate scalar loss\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Return average loss per batch\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce722fc",
   "metadata": {},
   "source": [
    "Selecting Best Available Device (CUDA, MPS, or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19088658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758273654514\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "# Prefer CUDA GPU → then Apple MPS → otherwise CPU\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "model.to(device)  # Move model to selected device\n",
    "\n",
    "with torch.no_grad():  # Disable gradients for evaluation\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232232f9",
   "metadata": {},
   "source": [
    "## 4.2 Training an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3f219",
   "metadata": {},
   "source": [
    "### 4.2.1 Simple GPT Training Loop with Evaluation and Text Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4698080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate and Print Sample Text During Training\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    \"\"\"\n",
    "    Generate a short text sample from the model during training.\n",
    "\n",
    "    Useful for qualitative monitoring of model progress.\n",
    "    Temporarily switches to evaluation mode for generation.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()  # Disable dropout and switch to inference mode\n",
    "\n",
    "    # Maximum context length supported by positional embeddings\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    # Encode starting text prompt and move to device\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "\n",
    "    # Generate tokens autoregressively\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "\n",
    "    # Decode tokens back to readable text\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    # Print generated text in one line (remove line breaks)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "\n",
    "    model.train()  # Restore training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca91dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \"\"\"\n",
    "    Train a GPT-style language model with periodic evaluation and sample generation.\n",
    "\n",
    "    Tracks:\n",
    "      - train_losses: training loss values measured during evaluation checkpoints\n",
    "      - val_losses: validation loss values measured during evaluation checkpoints\n",
    "      - track_tokens_seen: cumulative number of tokens processed at each checkpoint\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): GPT-style model to train.\n",
    "        train_loader (DataLoader): Training data loader yielding (input_batch, target_batch).\n",
    "        val_loader (DataLoader): Validation data loader yielding (input_batch, target_batch).\n",
    "        optimizer (torch.optim.Optimizer): Optimizer used for parameter updates.\n",
    "        device (torch.device): Device to run training on (cuda/mps/cpu).\n",
    "        num_epochs (int): Number of full passes over the training data.\n",
    "        eval_freq (int): Evaluate every eval_freq training steps.\n",
    "        eval_iter (int): Number of batches to use for evaluation (speed vs accuracy tradeoff).\n",
    "        start_context (str): Prompt text used for sample generation after each epoch.\n",
    "        tokenizer: Tokenizer used for encoding/decoding text.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_losses, val_losses, track_tokens_seen)\n",
    "    \"\"\"\n",
    "    # Lists used to store loss curves and token progress over time\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Enable training mode (dropout, etc.)\n",
    "\n",
    "        # Loop over batches\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset gradients from previous step\n",
    "\n",
    "            # Compute loss for current batch\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "\n",
    "            loss.backward()        # Backpropagate gradients\n",
    "            optimizer.step()       # Update model parameters\n",
    "\n",
    "            # Track how many tokens have been processed so far\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Periodic evaluation on train/val sets\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Generate a sample after each epoch to qualitatively inspect progress\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6af90d6",
   "metadata": {},
   "source": [
    "Model Evaluation Helper (Train & Validation Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cc69833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    \"\"\"\n",
    "    Evaluate model performance on training and validation sets.\n",
    "\n",
    "    Temporarily switches the model to evaluation mode\n",
    "    (disables dropout, etc.), computes average loss on a limited\n",
    "    number of batches for speed, then restores training mode.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Model to evaluate.\n",
    "        train_loader (DataLoader): Training dataset loader.\n",
    "        val_loader (DataLoader): Validation dataset loader.\n",
    "        device (torch.device): Computation device.\n",
    "        eval_iter (int): Number of batches to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loss, val_loss)\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()  # Switch to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "    model.train()  # Restore training mode\n",
    "\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dea767",
   "metadata": {},
   "source": [
    "### 4.2.2 Initializing GPT Model, Optimizer, and Starting Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e62793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.817, Val loss 9.924\n",
      "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.332\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.619, Val loss 7.042\n",
      "Ep 2 (Step 000015): Train loss 6.046, Val loss 6.596\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,, and,, the,, the, and,, and,,, the, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.524, Val loss 6.508\n",
      "Ep 3 (Step 000025): Train loss 5.369, Val loss 6.378\n",
      "Every effort moves you, and to the of the of the picture. Gis.                                     \n",
      "Ep 4 (Step 000030): Train loss 4.830, Val loss 6.263\n",
      "Ep 4 (Step 000035): Train loss 4.586, Val loss 6.285\n",
      "Every effort moves you of the \"I the picture.                    \"I\"I the picture\"I had the picture\"I the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.879, Val loss 6.130\n",
      "Every effort moves you know he had been his pictures, and I felt it's by his last word.                   \"Oh, and he had been the end, and he had been\n",
      "Ep 6 (Step 000045): Train loss 3.530, Val loss 6.183\n",
      "Ep 6 (Step 000050): Train loss 2.960, Val loss 6.123\n",
      "Every effort moves you know it was his pictures--I glanced after him, I had the last word.        \"Oh, and I was his pictures--I looked.   \"I looked. \"I looked. \n",
      "Ep 7 (Step 000055): Train loss 2.832, Val loss 6.150\n",
      "Ep 7 (Step 000060): Train loss 2.104, Val loss 6.133\n",
      "Every effort moves you know the picture to me--I glanced after him, and Mrs.  \"I was no great, the fact, the fact that, the moment--as Jack himself, as his pictures--as of the picture--because he was a little\n",
      "Ep 8 (Step 000065): Train loss 1.691, Val loss 6.186\n",
      "Ep 8 (Step 000070): Train loss 1.391, Val loss 6.230\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a little: \"Yes--and by me to me to have to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.059, Val loss 6.251\n",
      "Ep 9 (Step 000080): Train loss 0.800, Val loss 6.278\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back the window-curtains, I saw that, and down the room, and now\n",
      "Ep 10 (Step 000085): Train loss 0.569, Val loss 6.373\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)                    # Ensure reproducible initialization\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)         # Initialize GPT model\n",
    "model.to(device)                          # Move model to CPU/GPU/MPS\n",
    "\n",
    "# AdamW optimizer commonly used for Transformer training\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),                   # Model parameters to optimize\n",
    "    lr=0.0004,                            # Learning rate\n",
    "    weight_decay=0.1                      # Weight decay regularization\n",
    ")\n",
    "\n",
    "num_epochs = 10                           # Number of training epochs\n",
    "\n",
    "# Start training loop with periodic evaluation and sample generation\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea57d28",
   "metadata": {},
   "source": [
    "### 4.2.3 Plotting Training and Validation Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10cfc4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATyBJREFUeJzt3QdclPUfB/APe8mWISoIouLemjvT3CMrbZiZlpZaajZt2jBLy4aZpf3TLE3LcuQ2U9x774migqAgU/b9X9/fcceBSIDAHcfn/Xo93nru7rmfx32f3/xaaDQaDYiIiMgkWRr7AIiIiOjuGKiJiIhMGAM1ERGRCWOgJiIiMmEM1ERERCaMgZqIiMiEMVATERGZMAZqIiIiE8ZATUREZMIYqInMQFhYGCwsLHDo0CFjHwoRlTAGaiITIYG2oG3SpEnGPkQiMgJrY7wpEd0pIiJCf33x4sV47733cPr0af19lSpVYrERVUCsUROZCF9fX/3m6uqqatG6297e3pg+fTqqVasGOzs7NGnSBGvXrr3ra2VmZmL48OEICQnB5cuX1X3Lly9Hs2bNYG9vj6CgIHzwwQfIyMjQP0fe78cff8SAAQPg6OiIWrVqYcWKFfrHY2NjMXjwYHh5ecHBwUE9Pnfu3Lsew5IlS9CwYUO1r6enJ7p27YqkpCT94/JedevWVccjx/ndd9/len54eDgGDRoENzc3eHh4oH///qqJX+eZZ57BQw89hM8//xxVqlRR7zFmzBikp6cXo/SJTJhkzyIi0zJ37lyNq6ur/vb06dM1Li4umt9++01z6tQpzeuvv66xsbHRnDlzRj1+8eJFyYKnOXjwoCYlJUUzYMAATdOmTTVRUVHq8S1btqjnz5s3T3P+/HnN+vXrNTVq1NBMmjRJ/x7y/GrVqmkWLlyoOXv2rGbs2LGaSpUqaW7evKkeHzNmjKZJkyaavXv3qvfbsGGDZsWKFfke/7Vr1zTW1tbquGXfI0eOaGbOnKlJSEhQj//666+aKlWqaP7880/NhQsX1KWHh4c6PpGWlqapW7euZvjw4eq5J06c0Dz55JOaOnXqaFJTU9U+Q4cOVZ/phRde0Jw8eVLz999/axwdHTWzZ88utf8XImNgoCYqB4Haz89PM3ny5Fz7tGzZUjN69OhcgXrr1q2aLl26aNq3b6+5deuWfl+575NPPsn1/F9++UUFSx15/jvvvKO/nZiYqO5bs2aNut23b1/NsGHDCnX8+/fvV88NCwvL9/GaNWuqEwJDH330kaZNmzb6Y5OgnJWVpX9cArSDg4Nm3bp1+kAdEBCgycjI0O8zcOBAzWOPPVaoYyQqL9hHTWTi4uPjce3aNbRr1y7X/XL78OHDue574oknVPP4v//+q5qcdWS/7du3Y/Lkybmax1NSUpCcnKyaukWjRo30jzs5OcHFxQVRUVHq9qhRo/DII4/gwIED6Natm2p2btu2bb7H3LhxY3Tp0kU1fXfv3l3t/+ijj8Ld3V01f58/fx7PPvssRowYoX+ONMNLk7/ueM+dOwdnZ+dcryvHK8/VqV+/PqysrPS3pQn86NGjhS5bovKAgZrIjPTq1Qu//vordu7ciQceeEB/f2JiouqTfvjhh+94jvQR69jY2OR6TPqts7Ky1PWePXvi0qVLWL16NTZs2KACsfQJSx9xXhI8ZZ8dO3Zg/fr1mDFjBt5++23s3r1bf1IwZ84ctG7d+o7n6Y63efPmWLBgwR2vLX3khTleInPBQE1k4qRW6+fnp2rEnTp10t8vt1u1apVrX6n1NmjQAP369cOqVav0+8sgMhlBHhwcfE/HIkFy6NChauvQoQNee+21fAO1LmhKrV82GcEeEBCApUuXYsKECerzXLhwQQ1Oy48cr4x8l0F08vmJKjIGaqJyQALi+++/j5o1a6oR3zLaWhY3ya/G+dJLL6lm7T59+mDNmjVo3769CpRy29/fXzVBW1paqublY8eO4eOPPy7UMchrSC1XmptTU1OxcuVKNWo7P1Jz3rhxo2rylmArt6Ojo/X7S+1+7Nixqqm7R48e6vX27dunRpZLIJcAPm3aNDXS+8MPP1TN+VKb/+uvv/D666+r20QVBQM1UTkgQS0uLg6vvPKK6jOuV6+emjolU6TyM378eNUELE3hMo1L+oklsErQ++yzz1STsUyJeu655wp9DLa2tpg4caKaIiX931KjXrRoUb77Si14y5Yt+Oqrr1Qfu9Smv/jiC9V8LuR9pQlcgrGchEh/uPRny3ELeUye/8Ybb6jm+oSEBFStWlU1t7OGTRWNhYwoM/ZBEBERUf644AkREZEJY6AmIiIyYQzUREREJoyBmoiIyIQxUBMREZkwBmoiIiITxkB9FzNnzkSNGjXU8oqyzOGePXvK9n/GRMnc1r59+6qVpWTlqWXLluV6XGb7ycIYsuayzLWV1IZnz57NtU9MTIxa0ELmw0oKQ1nzWZaMNHTkyBE1T1fKv3r16pg6deodx/LHH3+oucCyj8zBlaUty7MpU6agZcuWan1rWSRE1tI2zEetW+talu2UlI6Sn1rW3r5+/XqufSStZe/evdVcZHkdmadsmM5SbN68Wa3+JSkzZbWyefPmVYi/gVmzZqn1zOW7J1ubNm3UojA6LN+S9emnn6rfCd38eJZxMRk7K4gpWrRokcbW1lbz008/aY4fP64ZMWKExs3NTXP9+nVNRbd69WrN22+/rfnrr79UdqSlS5fmevzTTz9VWZ+WLVumOXz4sKZfv36awMBAze3bt/X79OjRQ9O4cWPNrl27VLan4OBgzRNPPKF/PC4uTuPj46MZPHiw5tixYyq1o2RN+uGHH/T7bN++XWNlZaWZOnWqSoEoWZ8k7ePRo0c15VX37t1V1iz5zIcOHdL06tVL4+/vr7JY6UhKx+rVq2s2btyo2bdvn+a+++7TtG3bVv+4ZJJq0KCBpmvXrirlpfx/Va5cWTNx4kT9PpJWUtJBTpgwQZXdjBkzVFmuXbvW7P8GJC3nqlWrVHrQ06dPa9566y31vZEyFyzfkrNnzx6VSrVRo0aacePG6e9nGRcdA3U+WrVqpXLv6mRmZqo0g1OmTClGEZuvvIFaUhL6+vpqpk2bpr9PUi3a2dmpYCskMMjzJKexjqRRtLCw0Fy9elXd/u677zTu7u76vMPijTfeUGkPdQYNGqTp3bt3ruNp3bq15vnnn9eYC8klLWUVGhqqL0sJKn/88Yd+H8nDLPvs3LlT3ZbAbGlpqYmMjNTvM2vWLJW3WVeeksu6fv36ud5LUkPKiUJF/BuQ79qPP/7I8i1Bkne8Vq1aKmd5p06d9IGa3+HiYdN3Hmlpadi/f79qstWRdZHltmQkoru7ePEiIiMjc5WdrOUszaa6spNLae5u0aKFfh/ZX8pY1oPW7dOxY0e1ZKWOLIEpzcCyFrRuH8P30e1jTv9HsmSo8PDwUJfyvUxPT8/1uaXpX9bvNixf6Qbw8fHJVS6yjOfx48cLVXYV5W9A1kOXJVAl7aY0gbN8S450z0j3S97vGcu4eLjWdx43btxQf8CGP3RCbp86daqYxVwxSJAW+ZWd7jG5lH5TQ9bW1ioYGe4TGBh4x2voHpOcxnJZ0PuUd7JOt/TrSeYpyYYl5LPJyYuc6BRUvvmVi+6xgvaRYH779m11MmTOfwOSr1oCs/RHSz+/ZPSStdMlyQnL997JyY/kLN+7d+8dj/E7XDwM1EQmWiORzFbbtm0z9qGYnTp16qigLC0WS5YsUSk7Q0NDjX1YZiE8PBzjxo1TucgN85zTvWHTdx6VK1dWyevzjqSV276+vvdY3OZNVz4FlZ1cSvYnQzIiWUaCG+6T32sYvsfd9jGH/6MXX3xRZbratGlTrnSO8tmkWfrWrVsFlm9xy05GQctIfXP/G5Bas4x0l5SdMtK+cePG+Prrr1m+JUCatuXvW2YUSEuZbHIS9M0336jr0irD73DRMVDn80csf8CSS9ewGVJuS3MZ3Z00V8sPuWHZSXOq9D3ryk4uJdDIH7TOv//+q8pY+rJ1+8g0MOmP1ZEzdKkJSbO3bh/D99HtU57/j2R8ngRpaYqVMsnb/C/fS0lPafi5pd9epmMZlq807RqeDEm5SBCW5t3ClF1F+xuQzyb5sFm+907SkMr3T1osdJuMR5HpmLrr/A4XQzEHoZk1mZoiI5XnzZunRimPHDlSTU0xHElbUcloTpn2I5t8faZPn66uX7p0ST89S8pq+fLlmiNHjmj69++f7/Sspk2banbv3q3Ztm2bGh1qOD1LRobK9KwhQ4aoaTPy/yHTifJOz7K2ttZ8/vnnauTz+++/X+6nZ40aNUpNbdu8ebMmIiJCvyUnJ+ea2iJTtv799181PatNmzZqyzs9q1u3bmqKl0y58vLyynd61muvvabKbubMmflOzzLHv4E333xTjaK/ePGi+n7KbZlxsH79evU4y7fkGY76ZhkXDwP1XcjcUvlBlLmkMlVF5vySRrNp0yYVoPNuQ4cO1U/Revfdd1WglR/6Ll26qPmqhm7evKkCc6VKldS0oWHDhqkTAEMyB7t9+/bqNapWrapOAPL6/fffNbVr11b/RzLdSObHlmf5latsMrdaR054Ro8eraYUSbAdMGCACuaGwsLCND179lRzz2UO9SuvvKJJT0+/4/+xSZMmquyCgoJyvYc5/w0MHz5cExAQoD6TnMDI91MXpAXLt/QDNcu46Czkn+LUxImIiKj0sY+aiIjIhDFQExERmTAGaiIiIhPGQE1ERGTCGKiJiIhMGAM1ERGRCWOgLoCsVjRp0iR1SSWP5Vu6WL6lj2XM8i0LnEddAFn+UtI0yuL9sgQjlSyWb+li+ZY+ljHLtyywRk1ERGTCGKiJiIhMmNnno5YUigcPHlTp1Swti3ZekpCQoC6vXr2qmrioZLF8SxfLt/SxjFm+95K1TVLHNm3aVKUALYjZ91Hv3bsXrVq1MvZhEBER3WHPnj1o2bIlKnSNWmrSusKoUqWKsQ+HiIgIERERqhKpi1EVOlDrmrslSFerVs3Yh0NERKRXmC5Zow4m27JlC/r27Qs/Pz9YWFhg2bJluR6XVvn33ntPBVkHBwd07doVZ8+eNdrxEhERlTWjBuqkpCQ0btwYM2fOzPfxqVOn4ptvvsH333+P3bt3w8nJCd27d0dKSkqZHysREZExGLXpu2fPnmrLj9Smv/rqK7zzzjvo37+/um/+/PmqPV9q3o8//ngZHy0REVHZM9k+6osXLyIyMlI1d+vIKmGtW7fGzp077xqoZUk/wyU/ddMniIgKIzMzE+np6Swsuic2NjawsrKCWQdqCdIi74g4ua17LD9TpkzBBx98UOrHR0TmRVrx5Lfl1q1bxj4UMhNubm7w9fVVY7DMMlAX18SJEzFhwgT9bVmspF69eiXz4pkZwL8fAoGdgOAuJfOaRGQSdEHa29sbjo6O9/zjShX7pC85ORlRUVHq9r1ODTbZQC1nIUJWbjH8kHK7SZMmd32enZ2d2nRKckWx6/98BZ+dXwMHfgGeDwXc/EvstYnIuM3duiDt6enJ/wq6ZzJTSUiwlu/VvTSDm+xa34GBgSpYb9y4MVfQldHfbdq0KfPjiYi7ja5ba+FwVhBwOwZYPARI5+hzInOg65OWmjRRSdF9n+51zINRA3ViYiIOHTqkNt0AMrl++fJl1ew0fvx4fPzxx1ixYgWOHj2Kp59+Ws25fuihh8r8WKu4OuCRVsEYlTYesXABIg4Bq1+RNo4yPxYiKh1s7iZT/D4ZNVDv27dPLUgum5C+Zbkui5yI119/HS+99BJGjhyp1kKVwL527VrY29sb5Xjf7BkCZ59AjEl7EVlSdAd/BfbPM8qxEBFRxWDUQH3//ferTve827x58/RnIx9++KEa5CGLnPzzzz+oXbu20Y7X3sYKXz/RBPssG2Fq+iDtnWteB67sN9oxERGVtBo1aqh1LApr8+bN6ve6tEfMz5s3T42krmhMto/aVIX4uuDNHiH4PrMv1me1BDLTgN+HAInRxj40IqpgJDgWtE2aNKnYWQelJbOw2rZtq5JMyFoXVPJMdtS3KRvWrgZCz0RjwpnnscbxGqrHXwWWDAOGLAOsWKREVDYkOOosXrxYdRuePn1af1+lSpX016W1Uka3/1fuY+Hl5VWk47C1tdXP1KGSxxp1MciZ6rSBjWDn5IZht8chzdIBCNsKbORCK0RUdiQ46japzcpvk+72qVOn4OzsjDVr1qB58+Zq2uq2bdtw/vx5tSyzLB4lgVzG/0i3YkFN3/K6P/74IwYMGKBGMteqVUsN8r1b07euiXrdunWoW7euep8ePXrkOrHIyMjA2LFj1X4yJe6NN97A0KFDizxYeNasWahZs6Y6WahTpw5++eWXXCcn0qrg7++vPr8MRpb31Pnuu+/UZ5FxT1Iejz76KEwRA3UxeTvbY+qjjXBOUw3jU0Zo79zxDXBieQn+9xCRURetSMswyibvXVLefPNNfPrppzh58iQaNWqkBuX26tVLTX09ePCgCqCSxVBm2xREVnwcNGgQjhw5op4/ePBgxMTE3HV/WfDj888/V4FTMiXK67/66qv6xz/77DMsWLAAc+fOxfbt29X027wZFP/L0qVLMW7cOLzyyis4duwYnn/+eQwbNgybNm1Sj//555/48ssv8cMPP6jMi/L6DRs21A9mlqAt46CkFUIGKnfs2BGmiO2096BLXR883SYA83cCv1iGYUjWCmDVq0CtboCNdrI7EZVPt9MzUe+9dUZ57xMfdoejbcn8PEsgevDBB/W3PTw8VNZCnY8++kgFPKkhv/jii3d9nWeeeQZPPPGEuv7JJ5+ozIZ79uxRgT4/MndYMh9KbVfIa8ux6MyYMUOtJCm1dPHtt99i9erVRfpsn3/+uTqu0aNH62cO7dq1S93fuXNndXIgrQuSM0LW3paadatWrdS+8phkZOzTp49qeQgICNDPQDI1rFHfo7d61UUt70qYlDwQ2yp1h2bIXwzSRGQyWrRokeu21KilZitN0tLsLM3SUtv+rxq11MZ1JMC5uLjol8jMjzSR64K0kBUmdfvHxcWpVSZ1QVPIyl3SRF8UJ0+eRLt27XLdJ7flfjFw4EDcvn0bQUFBGDFihDohkSZ3IScvEpzlsSFDhqjavbQCmCLWqEtiytbjTfHQzO146sZQfBzmgqc4poKo3HOwsVI1W2O9d0mRoGpIgvSGDRtUrTM4OFgtdSl9s2lpaQW+jtRIDUmfdFZWVpH2L8km/cKoXr26ataWPnj5zFLznjZtGkJDQ1Ut+sCBA6p/ff369WognvRny4h3U5sCxhp1Cajn54LXe9RR1z9edQLnohKA8D3A3v+VxMsTkRFIYJHmZ2NspblCmvQHS3OxNDlLf600DYeFhaEsycA3GbwlQVFHRqRL4CyKunXrqs9jSG4bJmKSExHpg5emegnKkiZZVroUMgJemsWnTp2q+t6lHP7991+YGtaoS8jwdoFqytbWszcw7dcV+D5xHCw0mYBXCFAjd9MMEZGxyCjnv/76SwUvOSF49913C6wZlxZZdVLSEkutPiQkRPVZx8bGFukk5bXXXlMD3KRvWQLu33//rT6bbhS7jD6XE4DWrVurpvhff/1VBW5p8l65ciUuXLigBpC5u7ur/nEpBxk5bmpYoy6pgrS0wBcDG8PDyRbrolxxxKMbULcfUCVn0AYRkbFNnz5dBSZZpESCdffu3dGsWbMyPw6ZjiWD0ySHgyRakr5yOZaiLBH90EMP4euvv1bN+PXr11eju2UUuax6KaQJe86cOarfWvrYJYBLMJfpYPKYBPUHHnhA1cxl4Ntvv/2mXsfUWGjKutOgjF25ckX1U4SHh6NatWql/n4bTlzHiPn7YI0MzB3eBh1qe5f6exLRvZEliiUpkGTtM1YugYpOarMSMKWGLCPRzf17daUIsYk16hL2YD0fDG7tjwxY45U/jiAmKU2bYetc7gUFiIgqskuXLqna7pkzZ1Sf8ahRo1RQe/LJJ419aCaHgboUvNO7Hmp6OSEqIRVvLDkMzZLhwK+PAAfml8bbERGVO5aWlqoPWVZGk6ZpCdbSNC21asqNg8lKgYOtdsrWgO+2Y8PJKBxpWBWqp1oWQ/FpAFQt+/4gIiJTIs2+eUdsU/5Yoy4lDaq64vXuIer646faILFGNyAzFfj9aSDpZmm9LRERmRkG6lL0bPtAtA+ujNvpwLBbz0LjHgTEhQN/DgeyMkvzrYmIyEwwUJf2lK1BjeHuaIO9kZn4sepHgI0jcGEz8O/HpfnWRERkJhioS5mPiz0+fUS7Ru7kfRY43foT7QPbpgMnV5b22xMRUTnHQF0Gutf3xROt/NX1p/dUR0rz57UPLH0BuHG2LA6BiIjKKQbqMvJun7oI8nLC9fhUvBz7MDQBbYG0BGDxU0BqYlkdBhERlTMM1GVEFtr/5vGmsLGywJoTN7E8eDLgXAWIPgWseFG7KAoRkRHIkpvjx4/X365Rowa++uqrAp8ja3IvW7bsnt+7pF6nIJIVq0mTJiivGKjLeMrWq920C75PXB+FKw/OAixtgONLgZ0zy/JQiMgMyFrdPXr0yPexrVu3qiAoWaGKSrJajRw5EmURLCMiItCzZ88SfS9zw0BdxkZ0CELbmp64nZ6JUaE2yOg2GXDyBvyalvWhEFE59+yzz6o8y7JudF6SnKJFixYqGUVReXl5qWxTZUHSbNrZ2ZXJe5VXDNRlXeCWFpg+qAlcHWxw9GocPo/pCIzZzVSYRFRkffr0UUFVluI0lJiYiD/++EMF8ps3b6osVVWrVlXBV3JQS5aoguRt+j579qxKBymJJSTXs5wc5JcNq3bt2uo9goKCVPrM9PR09Zgc3wcffIDDhw+rWr5sumPO2/QtS4lKRitJRylZrkaOHKk+j47k0pasWZIxq0qVKmqfMWPG6N+rsAlAPvzwQ5UMQ04SpKa/du1a/eNpaWl48cUX1evLZ5a0mJKSU0geK2kd8Pf3V8/18/PD2LFjUZq4hKgR+Lra47NHGuKFXw/gh60X0LGOF9rWzH7w8i7AzhnwMb1Ua0QVUlpS0Z9jZQdYZf+8ZmZoVyW0sARsHP77dW2dCv021tbWKk2kBL23335bn8tZgrTkYZYALUGuefPmKpC6uLhg1apVGDJkCGrWrIlWrVoVKqg9/PDD8PHxwe7duxEXF5erP1vH2dlZHYcELgm2I0aMUPe9/vrreOyxx3Ds2DEVDHW5ol1dXe94jaSkJJXqUtJeSvN7VFQUnnvuORU0DU9GNm3apIKoXJ47d069vgRbec/CkNSYX3zxhUqLKbmsf/rpJ/Tr1w/Hjx9X+bq/+eYbrFixAr///rsKyJLhSjbx559/4ssvv8SiRYtUSszIyEh1AlJhA7V80eTMRZJ9S2HIF0DOpt55550iJRc3RT0aVMHjLatj0d5wTFh8GGvHd4DbzcPALw8Dto7A8HWApy56E5HRfOJX9OcMnAfUH6C9fupv4I9ngID2wLBVOft81RBIzmc54UlxRXqr4cOHY9q0aQgNDdXnYZZm70ceeUQFQ9leffVV/f4vvfQS1q1bp4JQYQK1BNZTp06p58hvsPjkk0/u6FeW32XDGrm8pwQzCdRSO5Z803JiIU3dd7Nw4UKVGnL+/PlwctKesHz77beqL/6zzz5TJwtC8mnL/VZWVggJCUHv3r2xcePGQgdqqY3Licvjjz+ubstrS9CXVoSZM2fi8uXLKmC3b99exRqpUevIY/IZunbtChsbGxXIC1OOZtv0LYU3a9Ys9R9y8uRJdXvq1KmYMWMGzMF7feshqLITIuNTMPGvo9B4BgOeQdrEHTIinIjoP0igatu2raoVCqlhykAyafbWVXgkv7M0eXt4eKiAKUFXAk5hyG+vJNDQBWkhNd68Fi9erLJgSRCT95DAXdj3MHyvxo0b64O0aNeunarVnz59Wn+f1GQlSOtI7Vpq34URHx+Pa9euqdc1JLfl/YVUCA8dOoQ6deqoZu3169fr9xs4cCBu376tmvflxGDp0qXIyMhAha1R79ixA/3791dnS7qzNOlb2bNnD8xlytZXjzfBw9/twJpjkfi9jhcee3qFdplRGyavJzIJb10rXtO3Tkhf7WtI07eh8UdRUiQoS01ZaoNSm5Zm7U6dOqnHpLYtTb1SW5RgLUFQmq6lH7ak7Ny5E4MHD1b90NJ0LbV4qU1L83JpsLGxyXVbar0SzEtKs2bNVG7sNWvWqBaFQYMGqRr0kiVL1EmLnDTI/dJXP3r0aH2LRt7jqhA1ajlLlOYMSSwupB9g27ZtZjWUv1E1N7ySPWXr3WXHsec6coK0zK2WaVvxxfihIKKSIX3GRd10/dNCrst9hv3TBb1uMUggkfzO0nQszcbSHK7rHpRUklLheeqpp1RtVWqCut/UwpD80NI/K9OodHbt2nVHpUqah6WfXEaaS7PxpUuXcn9cW1tVu/+v95Lfeemr1tm+fbv6bFK7LQnSTy+tA3lTbMptGShnuJ/0fc+ZM0e1FkjfdExMjHpMmvKlOV76sjdv3qxOVKRfvkLWqN98803VTCFNO9LMIf/JkydPVmdud5Oamqo2nYSEBJi65zsG4XD4Law9HomRv+zDX6PaIsirErD9a+Cf94F9PwHPrAactf0zRESGpKlZgsrEiRPVb6Y03epI0JSaoART6dudPn06rl+/nisoFURqkjKae+jQoarmKK8vAdmQvIc0c0stumXLlmrAmjQJG5IWUamlSpOyjLaWgWZ5p2XJb/v777+v3kvGJ0VHR6uWAhn8puufLgmvvfaaeh9peZBBaNIKIce1YMEC9biUkTSny0AzOUmQwXnSpO/m5qYGtUksat26tRrhLmOoJHAb9mNXqBq1DHaQgpOzxAMHDuDnn39WgwDk8m5kCL1uAIVshf0yGnvK1pePNUHj6m64lZyO4fP2IiYpDWjwMOBaHbh5Dpjfn3msiajA5u/Y2FjV9GzYnyx9xdKUK/fLYDMJODK9qfC/T5Yq6Eq/rAyaklHYUmEyJCOmX375ZTU6WwKfnBTI9CxDMrhNFmfp3LmzmlKW3xQxCXzSfy41Vwn4jz76KLp06aLGKZUk6XeeMGECXnnlFdUdIKPRZZS3nHAIOYmQ8VDSOiDHERYWhtWrV6uykGAttWzp05Y56tIE/vfff6tpYqXFQiOTwkyU9AVIrVrmyOl8/PHH6gxGRiEWpkZ99epVFayl6UbO4kxZdEIqBny3HVdib6N5gDsWPNca9vFhwLzeQEIE4NsQGPo34OBu7EMlMisy0lhqe4GBgWreLFFpf69kkRqJcYWJTSZdo05OTlZnMIakCbygQQPSlCJ9C7pNzozKCy9nO8wb1hIu9tbYfykWr/5xGFnuQYAMMHPyAiKPaqdvpcQb+1CJiKiMmHSgls56aWKR/g5pepDmF+k7GDAge36iGQr2dsb3Q5qr5B0rj0Tg8/WnAa/a2mDt4AFcOwAsGMiMW0REFYRJB2qZLy19FDL8XUYDygT6559/Xs0JNGdta1bGlIe16/N+t/k8Fu25DPjUA4YsBexcgfBdwG+PA2nJxj5UIiKqyIFamq1l7p8M85eBDOfPn1d91DLM39w92rwaxnbRDmx4e9kxbD0bDfg1AYb8BdhWAsK2AosHAxk5/fFERGR+TDpQV3Qvd62FAU2rIjNLg9G/HsDpyASgWgtg8B/aRVHO/wv8PhTIKLmFC4iIyLQwUJswWbDg00caolWgBxJSMzBs7h5ExacAAW2BJxYB1vbAmTXA0pHaxVGI6J6U5OpWRFkl9H0y6QVPCLCztsLsIc3x8KwduBCdhGd/3ofFz98Hx6BOwGMLgN+HACF9JKqzuIiKSbrTZIaJrAEtc3zldnlP/EPGI7OeZYlWWbBFvlf32l1r0vOoS0JR5qqZsks3kzDgux1qIZSudb3xw5AWsLK0ABKjgUpexj48onJPflhlmUyZFkpUEmQBF1nhLL9AXZTYxBp1ORHg6YQ5T7fAE3N24Z+TUfho5QlM6lc/d5CWNcEPLQA6vMoaNlERyY+ppCyUTEj/tSY10X+RNT8krWdJtMwwUJcjslrZl4OaYMzCA5i3IwwBno4Y1i5Q+2B6CjCvDxBzXnu742tGPVai8kh+VCUDUmllQSIqDg4mK2d6N6qCN3uGqOsfrjyBDSck3VZ2xq324wH3QKDRY8Y9SCIiKjEM1OWQZNt6opW/Gug99reDOHolTvtAs6eB0TsBN39jHyIREZUQBupy2jz3Uf/66FjbC7fTMzH85724Eps9AMYw5+3Jv4EdM4x2nEREdO8YqMspaytLzHyyKUJ8nVXWLUmNGZ+SnrND1CntYijr3wF2/2DMQyUionvAQF2OOdvb4KdnWsLHxQ5nrieq1cvSM7Mn2HuHAB0maK+veR2Y2wvYPw+4HWvUYyYioqJhoC7n/Nwc8L+hLeFoa4Vt527gnaXH1GR7pfPbQIdXpLEcuLQd+Hsc8HltYNFg4MQK7UhxIiIyaQzUZqBBVVd8+2RTyPoni/eFq4xbiszf6/Ie8PIxoOsHgHd9IDMNOLVSu6KZBO0VLwEXt8raicb+GERElA8GajPxQIiPdgEUANPWncaKw9dyHnStpp26NXoH8MJ2oN04wKUqkBoHHJgP/NwH+KohcPYf430AIiLKFwO1GXm6TQ082167AMqrfxzGvrCYO3fybQA8+CEw/hgwdKV2SpfkuI6/ArhWzdnv5nkg7koZHj0REeWHgdrMvNWrLrrX90FaRhZGzN+HizeS8t/R0hII7AD0mwG8egZ46k/Au27O45smA1824IhxIiIjY6A2M5Ko46vHmqJxNVfEJqer1JiSyKNAsqpZcNec2zIYLSVergDVWubcH3lUOzc7I7X0PgAREeXCQG2GHGyt8OPQlqjq5oCwm8kYOX8f4m4bzLH+LzII7aklwMvHAb+mOffv+h5Y/BTweS1gxVggbDsHoRERlTIm5TBTXs52mDespcpjve9SLNpO2aiWHR3ePlBN6SoUGYRmyD0AcPYDEq4BB37Wbtb2gIM74OCRfemWfZm9BXYCqjXXPl9q4olR2vvtKpX8hyYiMkPMR23m9l+KwdtLj+FUZIK6bW1pgX6N/TCiYxDqVnEp+gtmZWrnZB9ZrJ2LnSpN5AWQgWsyylxcPQDM6awdcT7hRM4+K18GEiINAnx2sK/kCzhXAVyqAE7egBXPK4nIPDAfNek1D/DAmnEdEHomGj+EXsDOCzfx18GrautU2wvPdwpCmyDPwudMtbQCAjtqt95fAgkR2tXO7rb5Nsx5bloiYGWrDcKGZB73zbMFv6+FJVDJB3CW4O0HNH4MqNdf+5gs3BJ7UftY3tcmIirnWKOuYI5cuYUftlzAmqMRyMpewKxhVVcVsHvU91VriJcqGagmTeAygE3n9Nr8A77UsuV+udRk5n6dbh8DbV/KXVOX2vcrp3L2CZ2qrfFLYJcg7pJ9KftZ25Xu5yQiKgBr1HRXjaq5YeaTzXD5ZjJ+3HYBv+8Lx9GrcXhx4UFU93DAiA5BGNi8uhqQViqk5m4YpEWdHv/d3J50Q9s3Hi+BOwKo3jrn8dQEwN5NG4QNHVqorWnnx95VW0OXJvVKsvkAlbyAoM5A1WY576vJAqxsivVRicjEZaQCyTHA7RjtZfLN7Os3geRYg+vZl9JC+NgvZX6YrFFXcDJ1a/7OMPy8I0xN5xLujjZq8ZSn2wTAs1I5qnlmpucOqrtnA7Fh2bXyCCD+mrZ2nlnA9LLunwBtxmivX9kH/NgF8GkIjNqWe/R7RkpOcFeXPoCjp7ZrQMiSrFkZQFa69rhk0J3uBCX9NhB3VTuX3SMo53WvHdK2AMjzMjNyni+X0hIhLQFu1bUtBOyvp4omK0u7BLLub0pt+d2Wv580oEb73L8FV/YAzYZq148Qp1YDi54o2jFUaQw8v6VEPg5r1FRoHk62GN+1Np7vWBNL9odjztaLuByTjK83nsUPW86r2vVzHQIR4Olk+qWat+bbeuSd+0jAk2b1pGgg8bp2FLrarmvv822Us6/cn9/r7voOuHUp/350SxvtD4fUxA31+BS4b1ROQJ7bA/CoCYw9kLPP8jHA9WP//TktrLSryLn6A00HA02e1N4vP1TxV7WD9dgKQP/ZBZWiPWmUS3VdLm/nuUzRBj1bp5wxIeLgr9q/j4aPAm7+2vsu7wJOLM8+wZRgKSeZmTknm7lOQLM3ed0nF+e87p/PAZd3A72m5bS0HV8GLBl+Z/dXQSytgXdvaFvwRNgW7RoQ0hKnC9TSqqb+niy1Y1vkRFtmr8ilo7vB9exLuS2tb0Zg8sNor169ijfeeANr1qxBcnIygoODMXfuXLRo0cLYh2ZWpKl7SJsaagrX2uORmL3lAo5cicMvuy5hwe5L6NmgCkZ2DELj6m4o1+QPV/3heQBedQret3YP4LXzQHpy7vsbDQJuhecEd3V5Qxuc71Zblx8lHekft3PR/kgZ8gjU7ic/MrpNAq5cymtLi4As6yo/fLcua7fgLjnPv3EGmNVW+6Py+oWc+w/9pn2Oa3Xtj6pMuytOH738uBsOOrxxFkiJA9KStD/46UlAWrK2vHT3yeBB+ZyyyZQ8SQwjKViF/JBLucn9ds5FPx5zl3RT+/1Kzy5LVbYGZazKOfs+Vf4p2imUnV7PeY35D2m/n4/9CnjWzBm7ISsPFoVncO5AvXMmEHVC202kC9TXj2tPYotCFyx1JPjHXdZ2Z+lYWt09SMv3S23yd2KTfd0asHHUlo/ub6zRY0D1+wD/+3KeK4s5vRGmXUJZWrdMmEkH6tjYWLRr1w6dO3dWgdrLywtnz56FuztH9pYWGUzWp5Efejesgl0XYlStevPpaKw6GqE2GSE+slMQ7q/tVfiR4uWV/PE6Vb7z/gfeufM+qSlIH5YERBVk5YfDKifQym0d+XGbGH7na8iPaWGa/xIjtScKEqhl7XYdCXpWdnfOf982XRvE9Sy0/fnyAyub9O/nDbStXwDq9tHuHrYN+PVR7Q/9qO05L/Pb48DNcyiSTm8A3m9pr8dcAGa20tZm5AdTZ+kLQOQxbQDXBXlbuW5w28Yhp9YmW/WWOavrSYD7531tTanfNzmvu/EjbfOnrolU99ws3e3sJlNZkU/+z6Tlol4/oOdn2udnpAGzO2n/X4etzVkLYPvXwNkN2f/PVjnPVdfz3JYaqpSxNKF2nphzbF+EaFcDfGm/djqi2DIV2P190cq3aovcgVr+36WVxXAapRyPITk2KU/VPaO7tNdeqs1OOxDTUEgf7fdYunx05DO1fzn7u2+d5/ufZ1P3WwHWedZ0kLKW8pGTVp2aXYAJp7TPUZttzt9XYX+D6va98z5rW+1WDph0oP7ss89QvXp1VYPWCQw0+A+kUiNBuE1NT7WdioxXNewVh66p6V2yhfg6q4FnfRv7wdbatM9Gy4ScxTsb/GiV5smD/GjK5m8woE4EdQLejgTSDGojIvhBwC0gpxYuzZq6fvvw3fm/T52eBu9po32OTK8zJE3sErxsHbU1GBVA5bpDTjCVQCi1a3muXBr2ycsJgQRTCcCGJLhcP1q0cmnzYk6glmM9+Iv2B90wUEuN72IR+xelxUBHTgykFikMA0T0aSBsa9FeN2/LS2pids3YoPVGTqDkJMZGTk6yy1V/PU956y7znqQN+F7bGiPdLDqtRgBNn8oJzMXpJnng7Tvvq9ZCu90Lw3wDOrbyWR1RkZn0YLJ69eqhe/fuqtM9NDQUVatWxejRozFixIhS6bCngl27dRtzt1/Ewt2XkZSmbYrycbHDk60C8ESr6vB2yTOam0yP/LlLzV/62FXgDtfWtgx/+OVH0bcxUDlY+xxpUpVavK0z4ORZ8scjtVjDpviII9omXxXgdUE+O9CnZl+Xmqm+ZmajPUnRNc3KPlITldfUTeHTzdeXZmDDWpmulmZ4XVocpKlV+ldl8R33GtrnS41bArI8JrMDdAMHr+zXzi6QgKj6XjOzBwBmv4bhbRUcHbUtGTU75xxb1Clt7U66Jzi+oEK4UoTYZNKB2t5e+8M/YcIEDBw4EHv37sW4cePw/fffY+jQofk+JzU1VW2GfdwS8BmoS46sGy7B+qftFxGdkKpf8axHA181WrxlDXfzbxYnIroHZhOobW1t1aCxHTt26O8bO3asCtg7d+7M9zmTJk3CBx98cMf9DNQlT1JprjkWgV92XlLrietIs/iQNgF4qElVONmZdO8KEZHJB2qT7lysUqWKqg0bqlu3Li5fvnzX50ycOBFxcXH67cQJgzWlqURJ33T/JlWxZFRbrBrbXjV/O9hYqXXFZX3x+z7ZiEkrjuN8dJ6+TSIiKrRiBWo5A5CzAZ09e/Zg/PjxmD17NkqSjPg+ffp0rvvOnDmDgICAuz7Hzs4OLi4u+s3ZmdM+ykJ9P1dMebgRdr3VBe/2qYcano5ISM3AvB1h6PJFKJ76cTfWHY9ERmae+cVERFTygfrJJ5/Epk2b1PXIyEg8+OCDKli//fbb+PDDD1FSXn75ZezatQuffPIJzp07h4ULF6qTgTFjsleOIpPj6mCDZ9sH4t9X7sfPw1uha11vNUB227kbeP6X/eg0bTNmbjqHG4kFrA5GRET31kct85glgNapUwfffPMNFi9ejO3bt2P9+vV44YUXcOGCwWIL92jlypWqOVvmT8vULBlYxlHf5Ut4TDIW7L6MxXsv65cptbWyRK+GvmqRlWb+bhx8RkQVypUi9FEXa6RPenq6amIW//zzD/r166euh4SEICIiAiWpT58+aqPyq7qHI97sGYLxXWth1ZEIzN91CYfDb2HZoWtqq+/ngqFtaqg52aWWDISIqCI1fdevX19Nkdq6dSs2bNiAHj20a7Jeu3YNnp4lPM+SzIa9jRUeaV4Ny8e0w4oX2+HR5tXUgLTj1+Lx+p9HcN+UjZi86gQu3Uwy9qESEZXvpu/NmzdjwIABiI+PV/OZf/rpJ3X/W2+9hVOnTuGvv/6CqeCCJ6YtNilNpdr8dfclhMfcVvdJn3an2l5oFeiBau6OqObugGpuDqhcyQ6WlpyfTUTlX5nMo87MzFSB2nDd7bCwMDg6OsLb2zgZRvLDQF0+ZGZpEHomCvN3XlJri+dHat8SsKtK4FabI6q6aa/Lfd7O9rBiICeicqDU+6hv374Nie+6IH3p0iUsXbpUzXGWJT+JikoC7AMhPmqTpu/lh64h7EYSrsTextVbtxERd1stsHLhRpLa8mNjZQE/XeBWl4451z0c4eNsp5KOEBGVJ8UK1P3798fDDz+sRnjfunULrVu3ho2NDW7cuIHp06dj1KjsvLtExSC5r8d2qZXrvvTMLETGpajAfSU2OftSgrj2ekRcCtIzNbh0M1lt+ZFlTn1d7RHsXQmDWlRHt3o+DNxEZJ6B+sCBA/jyyy/V9SVLlsDHxwcHDx7En3/+iffee4+BmkqcjZWlGj0uG3DngEVZSOV6QiquxCTra+G6gC7XJaGIBHJdgJfmdT9X++wc3NXh5lg+0t0RUcVTrECdnJysX/FL5k5L7drS0hL33XefagYnKmvSpC1N3LLlSf6o7wOPStDWyENPR2Phnsu4FpeCz9aewtcbz2BA06p4pm0g6vhyJTsiMi3F6rALDg7GsmXLVCf4unXr0K1bN3V/VFSUWraTyBT7wKu4OqBlDQ+82r0Odrz5AKY+2gh1q7ggJT0Lv+0JR/evtuDJObuw4cR1FdiJiMptjVqat2UZUVni84EHHkCbNm30teumTZuW9DESlcqcbumnHti8GvZcjFFrksta5DvO31Sbv4cjnm4TgEEtq8PFXnIUExEZR7GnZ8ka37IKWePGjVWzt5D1vqVGLSuUmQpOz6JCf1dik/HLrktYtCdc5dwWjrZWamGWoW1roKZXJRYmEZW/fNS6LFr/9UbGwkBNRZWcloFlB69h3o6LOHM9J0WnLMIyrF0NdKzlxYVXiMi081FnZWWpLFmurq4q5aRsbm5u+Oijj9RjROWZo601nmztj3XjO2LBc631GcBCz0Tjmbl70fXLUMzfGYbE1AxjHyoRVQDF6qOWdJb/+9//8Omnn6qc0WLbtm2YNGkSUlJSMHny5JI+TqIyZ2FhgXbBldUmi7D8vOMS/tgXjgvRSXhv+XFMW3ta9WFLQhF/T5k2RkRU8orV9O3n56eScuiyZuksX74co0ePxtWrV2Eq2PRNJUlq0X/uv4Kfd4TpV0iT2naXEB/VLN62pidTdhKR8ZcQjYmJyXfAmNwnjxGZq0p21mpg2ZD7AhB6NhrztoepJvF/Tl5Xm5ezHRr4uaBBVVfU93NFg6ouam631M6JiIqjWIFaRnp/++23+Oabb3LdL/c1atSoWAdCVJ5IFq/OdbzVdi4qUfVZL9l/BdEJqdh0OlptOm6ONmjg54r6VV3UpQTxAA9HDkgjotJr+g4NDUXv3r3h7++vn0O9c+dOVYVfvXo1OnToAFPBpm8qK7fTMnEiIh7Hr8Xh2FXZ4nHmegIy8lk8RWrm9aTmnV3rluAdVNmJa48TVRBXSrvpu1OnTjhz5gxmzpyp8k8LWUZ05MiR+Pjjj00qUBOVFQdbKzQPcFebTmpGJs5EJuKYLnhfi8fJiHjV1y0LrcimY29jqVZK0wVvaTqv7eOs0nsSUcV1z/OoDR0+fBjNmjVTuapNBWvUZGokE9j56ERV45bgLTXw49fikZyWmW/qTll/vGFVVwxuHaBq3kRU/pV6jZqI7i0TWIivi9pk1TORlaXBxZtJKnCfuBafXQOPVyukaQN6PBbtDcejzarhte514O1iz/8CogqCgZrIRAanyRKlsvVvUlXdJ41dku1Latyrjkbi78PX8Mf+K1h1NAKjOtXEiI5Bas1yIjJv7PwiMlEypUvyb/doUAUznmiKv0a3RVN/N9VE/sWGM3jg881YfuiqCuhEZL6KVKOWAWMFuXXr1r0eDxHdRTN/d/w1qi1WHL6Gz9acUvm0xy06hLnbw/Bun7poHuDBsiOq6IFa1vb+r8effvrpez0mIiqgli1N493r++LHrRfw3ebzOBR+C4/M2ok+jargzZ4hqObO5UyJzEmJjvo2RRz1TeYsKj4FX6w/g9/3h0P+kmUq13PtAzG6c7Caq01EFTR7FhGZBhn9/dmjjbDypfZoE+SJtIwsVcu+f9pmLNpzGZn5LLZCROVLuQrUkq1Lmv7Gjx9v7EMhMimyOMrCEa0xe0hz1PB0xI3EVLz511H0mbENO87dMPbhEVFFCNR79+7FDz/8wLXEie5CTmK71ffF+pc74Z3edeFib61WQXvyx9147ud9uBCdyLIjKofKRaBOTEzE4MGDMWfOHLi75yzPSER3Uv3UHYKw+bXOGNomAFaWFiqzV7cvt+CDv4/jVnIai42oHCkXgXrMmDEqCUjXrl3/c9/U1FTEx8frt4SEhDI5RiJT4+Fkiw/6N8C68R3QuY6XSg4iU7nu/3wz5m6/qJYyJSLTZ/KBetGiRThw4ACmTJlSqP1lP5kmptvq1atX6sdIZMqCvZ0xd1grzB/eCrV9KuFWcjo++PsEun+1BRtPXueCKUQmzqQDtQxbHzduHBYsWAB7+8KtbTxx4kTExcXptxMnTpT6cRKVBx1re2H12A6YPKABPJ1scSE6Cc/+vA+P/bAL/9t2UeXVNvPZmkTlkknPo162bBkGDBgAK6uc9YwlM5cMmrG0tFTN3IaP5YfzqInuFJ+SjpmbzmHutjCkGTSBV3VzUAG9U20vtA32hIu9DYuPqBQUJTaZdKCW/uVLly7lum/YsGEICQnBG2+8gQYNGvznazBQExXw9xGbjDVHI7HlbDR2X4jJFbRlEFpzf3d0quOFjrW8UN/PRSUPIaJ7ZzZpLp2dne8Ixk5OTvD09CxUkCaigslyo5KFS7bktAwVrEPPRGPLmWhcuJGEPWExapu27rRqLtfVttvXqozKlexYvERlwKQDNRGVHUdba3QO8VabCI9JVkFbNlk05WZSGpYevKo20bCqqwraErwlq5fk2SaikmfSTd8lgU3fRPdOliY9cDlWG7hPR+NERHyux53trNEuuLIK2h1rV2ZiEKKK0kddEhioiUpeVEIKtp65oQL31rPRiE1Oz/V4sHcl1a/dv4kfGld3438BUR4M1MUsDCIqOkn8cexqnL6Z/ODlWBjmAmkd6IGRHYPQuY43B6MRmdtgMiIyfTI6XGrNso3tUgtxyenYfv4G1h+PxKqjEdh9MUZtUsse2SEI/Zv6wc664GmVRJSDTd9EVGoi41LUcqULd19GQmqGus/b2Q7PtKuBwa0C4OrIedpUMV1hH3XxCoOISkdCSjoW7QnHT9svIiIuRd3nZGuFx1r6Y3j7Ghx8RhXOFQbq4hUGEZX+6PGVR65h9pYLOBWZoG86792wiurHblDVlf8FVCFcYR81EZlqCs6Hm1XDgKZVseXsDczZcgHbzt3AisPX1NYu2BMjO9ZEx1qV1VLBRMTBZERkBBKEZbEU2WTE+JytF7DySAS2n7upthBfZ4zoEIS+jf1UcCeqyDiYjIhMZt1xyZe9aM9lJKVlqvt8XexVH/YTrfzhzAQhZEbYR13MwiAi45PpXQv2XFJBOzohVb/y2ROt/TGsXQ1UcXUw9iES3TMG6mIWBhGZjtSMTCw/eA2zt15QubKFtaUF+jXxw/B2gajj68z1xanc4mAyIir3ZFGUQS2r49Hm1bD5TBR+CL2gFk7568BVtclYM8no5eNin73ZwdtZe93XNee67MP0nFSecWUyIjJpEmQfCPFR2+HwW2pq14YT11Xu7BuJaWo7fi13khBDUgv3craDtwRwFzt9YJeFV7RB3R4+zvZwcbDmSHMySQzURFRuyDKlMwc3Q1aWBrHJaYiMT0FUfCqux6fgulwmyO0Udb/cvpGYiowsjVpkRbbDBby2nbWlCtySsvOVB+vA39OxDD8Z0d0xUBNRuaxle1ayU1t9v7vvl5Fd69YGct2WHdgTUlVQl+uS/Ss1IwuXY5LVtuZYJEZ0CMTo+4PhZMefSTIufgOJyGxZW1mqpm3ZCpKSnqlGmIfHJGNW6HlsPXsDMzedx5/7r2JirxD0a+zHZnEyGq4kQEQVnr2NFap7OKJtcGXMH94Ks4c0R3UPB9WEPm7RIQz8fqdamIXIGBioiYjyrJrWrb4vNrzcCa91rwMHGyvsuxSLvt9uw8S/juBmonZuN1FZYaAmIrpLLXtM52D8+2on9G/iB40G+G1POO7/fDN+2nYR6ZlZLDcqEwzUREQFkJXQvn68KZa80AYNqrogISUDH648gV5fb8XWs9EsOyp1DNRERIXQooYHlo9pjykPN4SHky3ORiViyP/2YOT8fbh8M5llSKWGgZqIqJAkd7YkCNn0yv1q3XG5vf7EdXT9MhTT1p1CUmoGy5JKHAM1EVERuTra4P2+9bF2XAe0D66MtIwsNZ2ryxehWH7oKjTSoU1UQhioiYiKqZaPM355thV+4HQuKkUM1ERE9zidq3v2dK5Xu9XmdC6qWIF6ypQpaNmyJZydneHt7Y2HHnoIp0+fNvZhERHlO53rxQdqcToXVaxAHRoaijFjxmDXrl3YsGED0tPT0a1bNyQlJRn70IiICpzO9ccLbVDfL/d0rt/3hSMuOZ0lR0VioSlHox6io6NVzVoCeMeOHUs8OTcRUUnKzNKo4Dxt3WnEJKXp0262C66MXg190a2eL9ydbFnoFdCVIsSmcpWUIy5Ou9auh4fHXfdJTU1Vm05CQkKZHBsR0d2mc/VqUAXzd4Zh5ZEInL6egNAz0Wp7a+kxtK3piV4Nq6h+bpmfTVRua9RZWVno168fbt26hW3btt11v0mTJuGDDz64437WqInIFJyLSsSaoxFYfSwSJyPicwX1+4I89EG7ciU7ox4nmU6NutwE6lGjRmHNmjUqSBf0ofLWqK9evYp69eoxUBORybkQnahyX68+GoHj13KCtqUF0DrQE70aSdD2gbdzwWk6qfwxu0D94osvYvny5diyZQsCAwOL9Fz2URNReXDpZhJWH9UG7aMGKTUtLIBWNbQ17Z4NfOHtwqBtDswmUMuhvfTSS1i6dCk2b96MWrVqFfk1GKiJqLwJj0lWAVuaxw+H38oVtFsEuGcH7SrwdWXQLq/MJlCPHj0aCxcuVLXpOnXq6O93dXWFg4NDoV6DgZqIyrMrsclYeywSq45G4ODlnKAtmge4q1p2z4ZVUNWtcL+JZBrMJlDLij/5mTt3Lp555plCvQYDNRGZi2u3buv7tPdfis31mL+HI1oFeqhmcrkM8HS8628oGZ/ZBOqSwEBNROYoMi4Fa45F6IN2Vp5fci9nu1yBu46PMyxllBqZBAbqYhYGEVF5lJCSroL1nosxajtyJQ5pmVm59nGxt0bL7KDdMtADDau6wsbKpBenNGtXzHXBEyIiupOzvQ3ur+OtNpGSnolD4bewVwJ3WIwK4vEpGdh4KkptwsHGCs0C3PTBu2l1dzjYWrF4TRADNRGRGSYIuS/IU20iIzNLzdPeGxaD3Rdj1OWt5HRsP3dTbcLGykLVslsFeqJVoDuaB3jA1cHGyJ+EBPuoiYgqmKwsDc5FJ2qDdnZzeWR8Sq59ZBxaiK+LWi2tfXBltA7yRCU71u1KCpu+iYjormRQWW0fZ7UNuS9ArVkRHnNbNZPvuXgTe8NicfFGklriVLa528NUMpGm/m4qoYgE7sbV3djHXUZYoyYiojtExaeowL3j/E1sO3sDl2OScz3uZKttXleBu1Zl1PKuxOlgRcAaNRER3RNZqrRPIz+1ics3k7H9/A1sO3cDO87dQGxyeq7BaTIdTGrauho3V00rOexwICKi/+Tv6Qh/T3+VtlP6uE9ExGP7OW3glj7u6IRULD14VW2ippcTOtTyUoG7dZAHXOw5MK242PRNRET3RKaDHbgUq4K2BO8jV+NguJSWpPBsXM1VX+Nu6u8OW+uKPYf7CudRExFRWU4HaxtcWW3iVnIadl24mR24b6qBaQcu31LbN/+eU3O4Ze52M393NK7uikbV3ODhZMv/sLtg0zcREZUoN0db9GhQRW26xCI7zukC9w3cTEpD6JlotelU93BQAVtq3nLZoKorp4NlY6AmIqJSVc3dEYNaylZd9W+fikzAzgs3ceTKLbXcqdS4ZXqYbKuOROjncQd7VdIG7+xad90qzrCzrnirpzFQExFRmc7hrufnojaduOR0HL0ah8MqcGuDd0RcCs5GJartzwNX9KunySIsjaq5onE1NzSq7opa3s6qD9ycMVATEZFRuTraqLnYsulEJaTgSHicCtyHr2gvY7MDumwLdl9W+0l/d4OqErzd9AHc3FJ8MlATEZHJ8Xa2R9d6svmo27J62pXY29m17jgcDr+FY1fjkJSWqVZSk80wU1jdKi5qU7X3Ki6o5VOp3DabM1ATEZHJs7CwQHUPR7XpFmHJzNLgQnSiyhR2JLvWfTIiQWUKk3XMZdORJVBrelVS/dwSvHWBvHIlO5g6BmoiIiqXrCwtUMvHWW0DW1RX96VlZOFsVAJOXJN1yhPUWuWyOEvc7XScvp6gtmWHrulfw9vZTl/zVpdVnBFYuZJJ9XszUBMRkdmwtbZEfT9XtelIs7kMTlNBWwJ4pDaIh91MQlRCKqISck8Vs7exRB2f3DXvEF9nlffbGBioiYjI7JvN/dwc1NalrrbPWySlZqipYrpat1yeikjA7fRMNYBNNkP+Ho5oEeCO6Y81KdPjZ6AmIqIKycnOGs0D3NWmI/3el25Kis/cAVxq5JJBzLNS2a+gxkBNRESUTfqmg7wqqa13I+3KaiI2KU0F7CyDNczLCgM1ERHRf3B3stWvZV7WKnb6EiIiIhPHQE1ERGTCGKiJiIhMGAM1ERGRCWOgJiIiMmFmP+o7KytLXUZEaHOcEhERGZsuJuliVIUO1NevX1eXrVq1MvahEBER3RGj/P39URALjSyCasYyMjJw8OBB+Pj4wNLy3lr6ExISUK9ePZw4cQLOzs4ldozmjGXGMuP3zDTxb9O4ZSY1aQnSTZs2hbW1dcUO1CUpPj4erq6uiIuLg4uLi7EPp1xgmbHM+D0zTfzbLD9lxsFkREREJoyBmoiIyIQxUBeBnZ0d3n//fXVJLLPSwu8Zy6ws8HtWfsqMfdREREQmjDVqIiIiE8ZATUREZMIYqImIiEwYA3URzJw5EzVq1IC9vT1at26NPXv2lN7/TDk3ZcoUtGzZUi0K4O3tjYceeginT5829mGVG59++iksLCwwfvx4Yx+KSbt69SqeeuopeHp6wsHBAQ0bNsS+ffuMfVgmKzMzE++++y4CAwNVedWsWRMfffQRuJxGblu2bEHfvn3h5+en/g6XLVuW63Epr/feew9VqlRR5di1a1ecPXsWpYWBupAWL16MCRMmqBF/Bw4cQOPGjdG9e3dERUWV2n9OeRYaGooxY8Zg165d2LBhA9LT09GtWzckJSUZ+9BM3t69e/HDDz+gUaNGxj4UkxYbG4t27drBxsYGa9asUatFffHFF3B3dzf2oZmszz77DLNmzcK3336LkydPqttTp07FjBkzjH1oJiUpKUn9xkvlLD9SZt988w2+//577N69G05OTioepKSklM4Bycpk9N9atWqlGTNmjP52Zmamxs/PTzNlyhQWXyFERUXJCnia0NBQllcBEhISNLVq1dJs2LBB06lTJ824ceNYXnfxxhtvaNq3b8/yKYLevXtrhg8fnuu+hx9+WDN48GCW413I79bSpUv1t7OysjS+vr6aadOm6e+7deuWxs7OTvPbb79pSgNr1IWQlpaG/fv3q+YNHVk3XG7v3LmzdM6gzIwsuSc8PDyMfSgmTVohevfuneu7RvlbsWIFWrRogYEDB6ruFVkzec6cOSyuArRt2xYbN27EmTNn1O3Dhw9j27Zt6NmzJ8utkC5evIjIyMhcf6OyrKh0h5ZWPDD77Fkl4caNG6pvRxJ7GJLbp06dMtpxlRey+Lz0tUozZYMGDYx9OCZr0aJFqltFmr7pv124cEE140qX1FtvvaXKbezYsbC1tcXQoUNZhPl488031XrVISEhsLKyUr9rkydPxuDBg1lehSRBWuQXD3SPlTQGaiqTWuKxY8fUmTvlLzw8HOPGjVP9+TJYkQp3Aig16k8++UTdlhq1fM+k35CBOn+///47FixYgIULF6J+/fo4dOiQOomWQVMsM9PFpu9CqFy5sjr71OW21pHbvr6+pfV/YxZefPFFrFy5Eps2bUK1atWMfTgmS7pWZGBis2bNVMo72WRAngxYketS86HcZMStpBw0VLduXVy+fJlFdRevvfaaqlU//vjjaoT8kCFD8PLLL6tZGlQ4ut/8sowHDNSFIE1pzZs3V307hmfzcrtNmzal8h9T3skYDAnSS5cuxb///qumg9DddenSBUePHlU1HN0mtUVpkpTrcqJIuUlXSt4pf9L3GhAQwKK6i+TkZDW+xpB8t+T3jApHfsskIBvGA+lOkNHfpRUP2PRdSNIPJk1D8uPZqlUrfPXVV2oI/7Bhw0rlP8YcmruleW358uVqLrWu70YGXci8Q8pNyihv/71M+ZD5wezXz5/UBGVwlDR9Dxo0SK1rMHv2bLVR/mRusPRJ+/v7q6bvgwcPYvr06Rg+fDiLzEBiYiLOnTuXawCZnDDLYFgpO+ku+Pjjj1GrVi0VuGVuunQfyHoRpaJUxpKbqRkzZmj8/f01tra2arrWrl27jH1IJku+Wvltc+fONfahlRucnvXf/v77b02DBg3U1JiQkBDN7Nmzy+B/pvyKj49XU/7kd8ze3l4TFBSkefvttzWpqanGPjSTsmnTpnx/v4YOHaqfovXuu+9qfHx81HevS5cumtOnT5fa8TB7FhERkQljHzUREZEJY6AmIiIyYQzUREREJoyBmoiIyIQxUBMREZkwBmoiIiITxkBNRERkwhioiYiITBgDNRGVOAsLCyxbtowlS1QCGKiJzMwzzzyjAmXerUePHsY+NCIqBiblIDJDEpTnzp2b6z47OzujHQ8RFR9r1ERmSIKypOIz3Nzd3dVjUrueNWsWevbsqTKZBQUFYcmSJbmeLyk3H3jgAfW4ZPAaOXKkyihk6KefflIZmOS9JDe0pDU1dOPGDQwYMACOjo4qy9CKFSv0j8XGxqoUnl5eXuo95PG8JxZEpMVATVQBSVq+Rx55BIcPH1YB8/HHH8fJkyfVY5K+tXv37iqw7927F3/88Qf++eefXIFYAr2kMpUALkFdgnBwcHCu9/jggw9U+skjR46gV69e6n1iYmL073/ixAmsWbNGva+8XuXKlcu4FIjKiVLLy0VERiGp+KysrDROTk65tsmTJ6vH5c/+hRdeyPWc1q1ba0aNGqWuS6pId3d3TWJiov7xVatWaSwtLTWRkZHqtp+fn0qPeDfyHu+8847+tryW3LdmzRp1u2/fvpphw4aV8CcnMk/soyYyQ507d1a1VEOS9F6nTZs2uR6T24cOHVLXpYbbuHFjODk56R9v164dsrKycPr0adV0fu3aNXTp0qXAY2jUqJH+uryWi4sLoqKi1O1Ro0apGv2BAwfQrVs3PPTQQ2jbtu09fmoi88RATWSGJDDmbYouKdKnXBg2Nja5bkuAl2AvpH/80qVLWL16NTZs2KCCvjSlf/7556VyzETlGfuoiSqgXbt23XG7bt266rpcSt+19FXrbN++HZaWlqhTpw6cnZ1Ro0YNbNy48Z6OQQaSDR06FL/++iu++uorzJ49+55ej8hcsUZNZIZSU1MRGRmZ6z5ra2v9gC0ZINaiRQu0b98eCxYswJ49e/C///1PPSaDvt5//30VRCdNmoTo6Gi89NJLGDJkCHx8fNQ+cv8LL7wAb29vVTtOSEhQwVz2K4z33nsPzZs3V6PG5VhXrlypP1EgotwYqInM0Nq1a9WUKUNSGz516pR+RPaiRYswevRotd9vv/2GevXqqcdkOtW6deswbtw4tGzZUt2W/uTp06frX0uCeEpKCr788ku8+uqr6gTg0UcfLfTx2draYuLEiQgLC1NN6R06dFDHQ0R3spARZfncT0RmSvqKly5dqgZwEZHpYx81ERGRCWOgJiIiMmHsoyaqYNjbRVS+sEZNRERkwhioiYiITBgDNRERkQljoCYiIjJhDNREREQmjIGaiIjIhDFQExERmTAGaiIiIhPGQE1ERATT9X/M+wctHcTaSAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss curves.\n",
    "\n",
    "    Shows:\n",
    "      - Loss vs epochs (primary x-axis)\n",
    "      - Tokens processed vs loss (secondary x-axis)\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss vs epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses,\n",
    "        linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "\n",
    "    # Ensure integer tick marks for epochs\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    # Secondary x-axis showing tokens processed\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for alignment\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create evenly spaced epoch values matching number of recorded losses\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "\n",
    "# Plot loss curves\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
